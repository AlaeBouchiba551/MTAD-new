{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !wget https://s3-us-west-2.amazonaws.com/telemanom/data.zip\n# !unzip -qq data.zip\n# !git clone https://github.com/ML4ITS/mtad-gat-pytorch.git","metadata":{"id":"L29vJy96EcN0","outputId":"8a4c6b44-af20-4a80-88e9-7e24ef9890a0","execution":{"iopub.status.busy":"2023-04-30T08:34:03.602371Z","iopub.execute_input":"2023-04-30T08:34:03.603613Z","iopub.status.idle":"2023-04-30T08:34:03.636342Z","shell.execute_reply.started":"2023-04-30T08:34:03.603574Z","shell.execute_reply":"2023-04-30T08:34:03.635354Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom torch.nn import DataParallel\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm","metadata":{"id":"aGkrIpBEE5xZ","execution":{"iopub.status.busy":"2023-04-30T08:34:03.638590Z","iopub.execute_input":"2023-04-30T08:34:03.638964Z","iopub.status.idle":"2023-04-30T08:34:06.972802Z","shell.execute_reply.started":"2023-04-30T08:34:03.638926Z","shell.execute_reply":"2023-04-30T08:34:06.971630Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:06.974831Z","iopub.execute_input":"2023-04-30T08:34:06.975787Z","iopub.status.idle":"2023-04-30T08:34:08.225646Z","shell.execute_reply.started":"2023-04-30T08:34:06.975744Z","shell.execute_reply":"2023-04-30T08:34:08.223921Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Sun Apr 30 08:34:08 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# smap_channels = pd.read_csv('/kaggle/input/data-smap/smap_train_md.csv')\n# print(\"Number of Channels : \", len(smap_channels))\n# smap_channels.head(5)\n# smap_channels = list(smap_channels['chan_id'].values)\n# len(smap_channels)\n# smap_data = []\n# for smap_channel in smap_channels:\n#     tmp_data = np.load(os.path.join('/kaggle/input/smaptrain/train', smap_channel + '.npy'))\n#     smap_data.extend(tmp_data)\n    \n# smap_data = np.array(smap_data)\n# print(\"Shape of SMAP Data : \", smap_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:08.230861Z","iopub.execute_input":"2023-04-30T08:34:08.232052Z","iopub.status.idle":"2023-04-30T08:34:08.241951Z","shell.execute_reply.started":"2023-04-30T08:34:08.232007Z","shell.execute_reply":"2023-04-30T08:34:08.240399Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# mydata= pd.read_csv('/kaggle/input/train-test/train.csv')\n# mydata = np.array(mydata)\n# mydata.shape\n\nmydata= pd.read_csv('/kaggle/input/msl-data/msl_train.csv')\nmydata = np.array(mydata)\nmydata.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:08.243884Z","iopub.execute_input":"2023-04-30T08:34:08.244680Z","iopub.status.idle":"2023-04-30T08:34:08.316925Z","shell.execute_reply.started":"2023-04-30T08:34:08.244644Z","shell.execute_reply":"2023-04-30T08:34:08.315047Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(1565, 27)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, RobustScaler   \ndef normalize_data(data, scaler=None):\n    data = np.asarray(data, dtype=np.float32)\n    if np.any(sum(np.isnan(data))):\n        data = np.nan_to_num(data)\n\n    if scaler is None:\n        scaler = MinMaxScaler()\n        scaler.fit(data)\n    data = scaler.transform(data)\n    print(\"Data normalized\")\n\n    return data, scaler","metadata":{"id":"HJe4WvA5FKiF","execution":{"iopub.status.busy":"2023-04-30T08:34:08.318732Z","iopub.execute_input":"2023-04-30T08:34:08.327317Z","iopub.status.idle":"2023-04-30T08:34:09.252335Z","shell.execute_reply.started":"2023-04-30T08:34:08.327276Z","shell.execute_reply":"2023-04-30T08:34:09.251117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# # smap_data_norm, scaler = normalize_data(smap_data)\n# smap_data_norm, scaler = normalize_data(smap_data)\n# smap_data_pt = torch.from_numpy(smap_data)\n# smap_data_pt.size()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:09.254316Z","iopub.execute_input":"2023-04-30T08:34:09.254707Z","iopub.status.idle":"2023-04-30T08:34:09.262411Z","shell.execute_reply.started":"2023-04-30T08:34:09.254667Z","shell.execute_reply":"2023-04-30T08:34:09.261063Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"my_data_norm, scaler = normalize_data(mydata)\nmy_data_pt = torch.from_numpy(mydata)\nmy_data_pt.size()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:09.263913Z","iopub.execute_input":"2023-04-30T08:34:09.265809Z","iopub.status.idle":"2023-04-30T08:34:09.294833Z","shell.execute_reply.started":"2023-04-30T08:34:09.265780Z","shell.execute_reply":"2023-04-30T08:34:09.293867Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Data normalized\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"torch.Size([1565, 27])"},"metadata":{}}]},{"cell_type":"code","source":"class SlidingWindowDataset(Dataset):\n    def __init__(self, data, window, target_dim=None, horizon=1):\n        self.data = data\n        self.window = window\n        self.target_dim = target_dim\n        self.horizon = horizon\n\n    def __getitem__(self, index):\n        x = self.data[index : index + self.window]\n        y = self.data[index + self.window : index + self.window + self.horizon]\n        return x, y\n\n    def __len__(self):\n        return len(self.data) - self.window","metadata":{"id":"-L3a6DZiFS7h","execution":{"iopub.status.busy":"2023-04-30T08:34:09.296091Z","iopub.execute_input":"2023-04-30T08:34:09.298364Z","iopub.status.idle":"2023-04-30T08:34:09.310016Z","shell.execute_reply.started":"2023-04-30T08:34:09.298327Z","shell.execute_reply":"2023-04-30T08:34:09.308878Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **修改参数部分**","metadata":{}},{"cell_type":"code","source":"Window = 100\nWindow_1 = 80\nWindow_gap = Window - Window_1\nBatchSZ =  256\nnumber_features = 27\nEPOCHS =  100\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice1 = torch.device('cuda:0')  # 选择第一个GPU设备\ndevice2 = torch.device('cuda:1')  # 选择第二个GPU设备","metadata":{"id":"dRvPpy1vFV28","execution":{"iopub.status.busy":"2023-04-30T08:34:09.319079Z","iopub.execute_input":"2023-04-30T08:34:09.321971Z","iopub.status.idle":"2023-04-30T08:34:09.441473Z","shell.execute_reply.started":"2023-04-30T08:34:09.321933Z","shell.execute_reply":"2023-04-30T08:34:09.440072Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# smap_x_y = SlidingWindowDataset(smap_data_pt, Window)\nmy_x_y = SlidingWindowDataset(my_data_pt, Window)","metadata":{"id":"5B7ur4FdFZDM","execution":{"iopub.status.busy":"2023-04-30T08:34:09.443087Z","iopub.execute_input":"2023-04-30T08:34:09.443484Z","iopub.status.idle":"2023-04-30T08:34:09.452433Z","shell.execute_reply.started":"2023-04-30T08:34:09.443443Z","shell.execute_reply":"2023-04-30T08:34:09.451331Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_data_loaders(train_dataset, batch_size, val_split=0.2, shuffle=True, test_dataset=None):\n    train_loader, val_loader, test_loader = None, None, None\n    if val_split == 0.0:\n        print(f\"train_size: {len(train_dataset)}\")\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n\n    else:\n        dataset_size = len(train_dataset)\n        indices = list(range(dataset_size))\n        split = int(np.floor(val_split * dataset_size))\n        if shuffle:\n            np.random.shuffle(indices)\n        train_indices, val_indices = indices[split:], indices[:split]\n\n        train_sampler = SubsetRandomSampler(train_indices)\n        valid_sampler = SubsetRandomSampler(val_indices)\n\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n        val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n\n        print(f\"train_size: {len(train_indices)}\")\n        print(f\"validation_size: {len(val_indices)}\")\n\n    if test_dataset is not None:\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n        print(f\"test_size: {len(test_dataset)}\")\n\n    return train_loader, val_loader, test_loader","metadata":{"id":"hmne9YN0FciN","execution":{"iopub.status.busy":"2023-04-30T08:34:09.453916Z","iopub.execute_input":"2023-04-30T08:34:09.455055Z","iopub.status.idle":"2023-04-30T08:34:09.468015Z","shell.execute_reply.started":"2023-04-30T08:34:09.455014Z","shell.execute_reply":"2023-04-30T08:34:09.466521Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# train_dl, val_dl, _ = create_data_loaders(smap_x_y, BatchSZ)\ntrain_dl, val_dl, _ = create_data_loaders(my_x_y, BatchSZ)","metadata":{"id":"UkiCmSPUFfRM","outputId":"b96115c2-6d0c-4b1a-9d41-d28b99604e6c","execution":{"iopub.status.busy":"2023-04-30T08:34:09.472177Z","iopub.execute_input":"2023-04-30T08:34:09.472565Z","iopub.status.idle":"2023-04-30T08:34:09.483825Z","shell.execute_reply.started":"2023-04-30T08:34:09.472526Z","shell.execute_reply":"2023-04-30T08:34:09.482674Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"train_size: 1172\nvalidation_size: 293\n","output_type":"stream"}]},{"cell_type":"code","source":"eg = next(iter(val_dl))\neg[0].size(), eg[1].size()","metadata":{"id":"AheOZu1UFhY0","outputId":"1b1a2d40-80ca-4eb1-fb6b-28d2a96fcaf4","execution":{"iopub.status.busy":"2023-04-30T08:34:09.485623Z","iopub.execute_input":"2023-04-30T08:34:09.487163Z","iopub.status.idle":"2023-04-30T08:34:09.565633Z","shell.execute_reply.started":"2023-04-30T08:34:09.487122Z","shell.execute_reply":"2023-04-30T08:34:09.564650Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(torch.Size([256, 100, 27]), torch.Size([256, 1, 27]))"},"metadata":{}}]},{"cell_type":"code","source":"# import sys\n# sys.path.insert(0, 'mtad-gat-pytorch/')","metadata":{"id":"Lv99qXotFkmD","execution":{"iopub.status.busy":"2023-04-30T08:34:09.569890Z","iopub.execute_input":"2023-04-30T08:34:09.570226Z","iopub.status.idle":"2023-04-30T08:34:09.577483Z","shell.execute_reply.started":"2023-04-30T08:34:09.570198Z","shell.execute_reply":"2023-04-30T08:34:09.576495Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass ConvLayer(nn.Module):\n    \"\"\"1-D Convolution layer to extract high-level features of each time-series input\n    :param n_features: Number of input features/nodes\n    :param window_size: length of the input sequence\n    :param kernel_size: size of kernel to use in the convolution operation\n    \"\"\"\n    def __init__(self, n_features, kernel_size=7):\n        super(ConvLayer, self).__init__()\n        self.padding = nn.ConstantPad1d((kernel_size - 1) // 2, 0.0)\n        self.conv = nn.Conv1d(\n            in_channels=n_features, out_channels=n_features, kernel_size=kernel_size\n        )\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = x.permute(0, 2, 1)\n        x = self.padding(x)\n        x = self.relu(self.conv(x))\n        return x.permute(0, 2, 1)  # Permute back\n\n\n\nclass FeatureAttentionLayer0(nn.Module):\n    \"\"\"Single Graph Feature/Spatial Attention Layer\n    :param n_features: Number of input features/nodes\n    :param window_size: length of the input sequence\n    :param dropout: percentage of nodes to dropout\n    :param alpha: negative slope used in the leaky rely activation function\n    :param embed_dim: embedding dimension (output dimension of linear transformation)\n    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n    :param use_bias: whether to include a bias term in the attention layer\n    \"\"\"\n\n    def __init__(\n        self,\n        n_features,\n        window_size,\n        dropout,\n        alpha,\n        embed_dim=None,\n        use_gatv2=True,\n        use_bias=True,\n    ):\n        super(FeatureAttentionLayer0, self).__init__()\n        self.n_features = n_features\n        self.window_size = window_size\n        self.dropout = dropout\n        self.embed_dim = embed_dim if embed_dim is not None else window_size\n        self.use_gatv2 = use_gatv2\n        self.num_nodes = n_features\n        self.use_bias = use_bias\n\n        # Because linear transformation is done after concatenation in GATv2\n        if self.use_gatv2:\n            self.embed_dim *= 2\n            lin_input_dim = 2 * window_size\n            a_input_dim = self.embed_dim\n        else:\n            lin_input_dim = window_size\n            a_input_dim = 2 * self.embed_dim\n\n        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n        self.a = nn.Parameter(torch.zeros((a_input_dim, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n\n        if self.use_bias:\n            self.bias = nn.Parameter(torch.zeros(n_features, n_features))\n\n        self.leakyrelu = nn.LeakyReLU(alpha)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n        # C\n\n        x = x.permute(0, 2, 1)\n\n        # 'Dynamic' GAT attention\n        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n        if self.use_gatv2:\n            a_input = self._make_attention_input(x)  # (b, k, k, 2*window_size)\n            a_input = self.leakyrelu(self.lin(a_input))  # (b, k, k, embed_dim)\n            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, k, k, 1)\n            \n\n        # Original GAT attention\n        else:\n            Wx = self.lin(x)  # (b, k, k, embed_dim)\n            a_input = self._make_attention_input(Wx)  # (b, k, k, 2*embed_dim)\n            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, k, k, 1)\n            \n\n        if self.use_bias:\n            e += self.bias\n\n        # Attention weights    \n        attention = torch.softmax(e, dim=2)\n        attention = torch.dropout(attention, self.dropout, train=self.training)\n        # attention = \n        # Computing new node features using the attention\n        h = self.sigmoid(torch.matmul(attention, x))\n        return h.permute(0, 2, 1)\n\n    def _make_attention_input(self, v):\n        \"\"\"Preparing the feature attention mechanism.\n        Creating matrix with all possible combinations of concatenations of node.\n        Each node consists of all values of that node within the window\n            v1 || v1,\n            ...\n            v1 || vK,\n            v2 || v1,\n            ...\n            v2 || vK,\n            ...\n            ...\n            vK || v1,\n            ...\n            vK || vK,\n        \"\"\"\n\n        # K = self.num_nodes\n        # blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n        # blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n        # combined = torch.cat(\n        #     (blocks_repeating, blocks_alternating), dim=2\n        # )  # (b, K*K, 2*window_size)\n        K = self.num_nodes\n        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n        combined = torch.cat(\n            (blocks_repeating, blocks_alternating), dim=2\n        )  # (b, K*K, 2*window_size)\n\n        if self.use_gatv2:\n            return combined.view(v.size(0), K, K, 2 * self.window_size)\n        else:\n            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\nclass FeatureAttentionLayer1(nn.Module):\n    \"\"\"Single Graph Feature/Spatial Attention Layer\n    :param n_features: Number of input features/nodes\n    :param window_size: length of the input sequence\n    :param dropout: percentage of nodes to dropout\n    :param alpha: negative slope used in the leaky rely activation function\n    :param embed_dim: embedding dimension (output dimension of linear transformation)\n    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n    :param use_bias: whether to include a bias term in the attention layer\n    \"\"\"\n\n    def __init__(\n        self,\n        n_features,\n        window_size,\n        dropout,\n        alpha,\n        embed_dim=None,\n        use_gatv2=True,\n        use_bias=True,\n    ):\n        super(FeatureAttentionLayer1, self).__init__()\n        self.n_features = n_features\n        self.window_size = window_size\n        self.dropout = dropout\n        self.embed_dim = embed_dim if embed_dim is not None else window_size\n        self.use_gatv2 = use_gatv2\n        self.num_nodes = n_features\n        self.use_bias = use_bias\n\n        # Because linear transformation is done after concatenation in GATv2\n        if self.use_gatv2:\n            self.embed_dim *= 2\n            lin_input_dim = 2 * window_size\n            a_input_dim = self.embed_dim\n        else:\n            lin_input_dim = window_size\n            a_input_dim = 2 * self.embed_dim\n\n        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n        self.a = nn.Parameter(torch.rand((a_input_dim, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n\n        if self.use_bias:\n            self.bias = nn.Parameter(torch.rand(n_features, n_features))\n\n        self.leakyrelu = nn.LeakyReLU(alpha)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n        # C\n\n        x = x.permute(0, 2, 1)\n\n        # 'Dynamic' GAT attention\n        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n        if self.use_gatv2:\n            a_input = self._make_attention_input(x)  # (b, k, k, 2*window_size)\n            a_input = self.leakyrelu(self.lin(a_input))  # (b, k, k, embed_dim)\n            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, k, k, 1)\n            \n\n        # Original GAT attention\n        else:\n            Wx = self.lin(x)  # (b, k, k, embed_dim)\n            a_input = self._make_attention_input(Wx)  # (b, k, k, 2*embed_dim)\n            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, k, k, 1)\n            \n\n        if self.use_bias:\n            e += self.bias\n\n        # Attention weights    \n        attention = torch.softmax(e, dim=2)\n        attention = torch.dropout(attention, self.dropout, train=self.training)\n        # attention = \n        # Computing new node features using the attention\n        h = self.sigmoid(torch.matmul(attention, x))\n        return h.permute(0, 2, 1)\n\n    def _make_attention_input(self, v):\n        \"\"\"Preparing the feature attention mechanism.\n        Creating matrix with all possible combinations of concatenations of node.\n        Each node consists of all values of that node within the window\n            v1 || v1,\n            ...\n            v1 || vK,\n            v2 || v1,\n            ...\n            v2 || vK,\n            ...\n            ...\n            vK || v1,\n            ...\n            vK || vK,\n        \"\"\"\n\n        # K = self.num_nodes\n        # blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n        # blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n        # combined = torch.cat(\n        #     (blocks_repeating, blocks_alternating), dim=2\n        # )  # (b, K*K, 2*window_size)\n        K = self.num_nodes\n        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n        combined = torch.cat(\n            (blocks_repeating, blocks_alternating), dim=2\n        )  # (b, K*K, 2*window_size)\n\n        if self.use_gatv2:\n            return combined.view(v.size(0), K, K, 2 * self.window_size)\n        else:\n            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\n\n\nclass TemporalAttentionLayer(nn.Module):\n    \"\"\"Single Graph Temporal Attention Layer\n    :param n_features: number of input features/nodes\n    :param window_size: length of the input sequence\n    :param dropout: percentage of nodes to dropout\n    :param alpha: negative slope used in the leaky rely activation function\n    :param embed_dim: embedding dimension (output dimension of linear transformation)\n    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n    :param use_bias: whether to include a bias term in the attention layer\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_features,\n        window_size,\n        dropout,\n        alpha,\n        embed_dim=None,\n        use_gatv2=True,\n        use_bias=True,\n    ):\n        super(TemporalAttentionLayer, self).__init__()\n        self.n_features = n_features\n        self.window_size = window_size\n        self.dropout = dropout\n        self.use_gatv2 = use_gatv2\n        self.embed_dim = embed_dim if embed_dim is not None else n_features\n        self.num_nodes = window_size\n        self.use_bias = use_bias\n\n        # Because linear transformation is performed after concatenation in GATv2\n        if self.use_gatv2:\n            self.embed_dim *= 2\n            lin_input_dim = 2 * n_features\n            a_input_dim = self.embed_dim\n        else:\n            lin_input_dim = n_features\n            a_input_dim = 2 * self.embed_dim\n\n        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n        self.a = nn.Parameter(torch.zeros((a_input_dim, 1)))\n        #self.a = nn.Parameter(torch.rand((a_input_dim, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n\n        if self.use_bias:\n            self.bias = nn.Parameter(torch.zeros(window_size, window_size))\n\n        self.leakyrelu = nn.LeakyReLU(alpha)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n        # For temporal attention a node is represented as all feature values at a specific timestamp\n\n        # 'Dynamic' GAT attention\n        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n        if self.use_gatv2:\n            a_input = self._make_attention_input(x)  # (b, n, n, 2*n_features)\n            a_input = self.leakyrelu(self.lin(a_input))  # (b, n, n, embed_dim)\n            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, n, n, 1)\n\n        # Original GAT attention\n        else:\n            Wx = self.lin(x)  # (b, n, n, embed_dim)\n            a_input = self._make_attention_input(Wx)  # (b, n, n, 2*embed_dim)\n            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, n, n, 1)\n\n        if self.use_bias:\n            e += self.bias  # (b, n, n, 1)\n\n        # Attention weights\n        attention = torch.softmax(e, dim=2)\n        attention = torch.dropout(attention, self.dropout, train=self.training)\n\n        h = self.sigmoid(torch.matmul(attention, x))  # (b, n, k)\n        return h\n\n    def _make_attention_input(self, v):\n        \"\"\"Preparing the temporal attention mechanism.\n        Creating matrix with all possible combinations of concatenations of node values:\n            (v1, v2..)_t1 || (v1, v2..)_t1\n            (v1, v2..)_t1 || (v1, v2..)_t2\n\n            ...\n            ...\n\n            (v1, v2..)_tn || (v1, v2..)_t1\n            (v1, v2..)_tn || (v1, v2..)_t2\n\n        \"\"\"\n\n        K = self.num_nodes\n        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix\n\n        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix\n        combined = torch.cat((blocks_repeating, blocks_alternating), dim=2)\n\n        \n\n        if self.use_gatv2:\n            return combined.view(v.size(0), K, K, 2 * self.n_features)\n        else:\n            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\n\n\nclass GRULayer(nn.Module):\n    \"\"\"Gated Recurrent Unit (GRU) Layer\n    :param in_dim: number of input features\n    :param hid_dim: hidden size of the GRU\n    :param n_layers: number of layers in GRU\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n        super(GRULayer, self).__init__()\n        self.hid_dim = hid_dim\n        self.n_layers = n_layers\n        self.dropout = 0.0 if n_layers == 1 else dropout\n        self.gru = nn.GRU(\n            in_dim, hid_dim, num_layers=n_layers, batch_first=True, dropout=self.dropout\n        )\n\n    def forward(self, x):\n        out, h = self.gru(x)\n        out, h = out[-1, :, :], h[-1, :, :]  # Extracting from last layer\n        return out, h\n\nclass LSTMLayer(nn.Module):\n    \"\"\"LSTM  Layer\n    :param in_dim: number of input features\n    :param hid_dim: hidden size of the LSTM \n    :param n_layers: number of layers in LSTM \n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n        super(LSTMLayer, self).__init__()\n        self.hid_dim = hid_dim\n        self.n_layers = n_layers\n        self.dropout = 0.0 if n_layers == 1 else dropout\n        self.lstm = nn.LSTM(\n            in_dim, hid_dim, num_layers=n_layers, batch_first=True, dropout=self.dropout\n        )\n\n    def forward(self, x):\n        out, (h, c) = self.lstm(x)\n        out, h = out[-1, :, :], h[-1, :, :]  # Extracting from last layer\n        return out, h\n\n\n\nclass RNNDecoder(nn.Module):\n    \"\"\"GRU-based Decoder network that converts latent vector into output\n    :param in_dim: number of input features\n    :param n_layers: number of layers in RNN\n    :param hid_dim: hidden size of the RNN\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n        super(RNNDecoder, self).__init__()\n        self.in_dim = in_dim\n        self.dropout = 0.0 if n_layers == 1 else dropout\n        self.rnn = nn.GRU(\n            in_dim, hid_dim, n_layers, batch_first=True, dropout=self.dropout\n        )\n\n    def forward(self, x):\n        decoder_out, _ = self.rnn(x)\n        return decoder_out\n    \nclass LSTMDecoder(nn.Module):\n    \"\"\"LSTM-based Decoder network that converts latent vector into output\n    :param in_dim: number of input features\n    :param n_layers: number of layers in RNN\n    :param hid_dim: hidden size of the RNN\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n        super(LSTMDecoder, self).__init__()\n        self.in_dim = in_dim\n        self.dropout = 0.0 if n_layers == 1 else dropout\n        self.lstm= nn.LSTM(\n            in_dim, hid_dim, n_layers, batch_first=True, dropout=self.dropout\n        )\n\n    def forward(self, x):\n        decoder_out, _ = self.lstm(x)\n        return decoder_out\n\n\n\nclass ReconstructionModel_0(nn.Module):\n    \"\"\"Reconstruction Model\n    :param window_size: length of the input sequence\n    :param in_dim: number of input features\n    :param n_layers: number of layers in RNN\n    :param hid_dim: hidden size of the RNN\n    :param in_dim: number of output features\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, window_size, in_dim, hid_dim, out_dim, n_layers, dropout):\n        super(ReconstructionModel_0, self).__init__()\n        self.window_size = window_size\n        self.decoder = LSTMDecoder(in_dim, hid_dim, n_layers, dropout)\n#         self.decoder = RNNDecoder(in_dim, hid_dim, n_layers, dropout)\n        self.fc = nn.Linear(hid_dim, out_dim)\n        #self.sigma1 = nn.Parameter(torch.tensor(0.5))\n\n    def forward(self, x):\n        # x will be last hidden state of the GRU layer\n        h_end = x\n        h_end_rep = h_end.repeat_interleave(self.window_size, dim=1).view(\n            x.size(0), self.window_size, -1\n        )\n\n        decoder_out = self.decoder(h_end_rep)\n        out = self.fc(decoder_out)\n        #out = self.sigma1 * out\n        return out\n\nclass ReconstructionModel_1(nn.Module):\n    \"\"\"Reconstruction Model\n    :param window_size: length of the input sequence\n    :param in_dim: number of input features\n    :param n_layers: number of layers in RNN\n    :param hid_dim: hidden size of the RNN\n    :param in_dim: number of output features\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, window_size, in_dim, hid_dim, out_dim, n_layers, dropout):\n        super(ReconstructionModel_1, self).__init__()\n        self.window_size = window_size\n#         self.decoder = LSTMDecoder(in_dim, hid_dim, n_layers, dropout)\n        self.decoder = RNNDecoder(in_dim, hid_dim, n_layers, dropout)\n        self.fc = nn.Linear(hid_dim, out_dim)\n        #self.sigma1 = nn.Parameter(torch.tensor(0.5))\n\n    def forward(self, x):\n        # x will be last hidden state of the GRU layer\n        h_end = x\n        h_end_rep = h_end.repeat_interleave(self.window_size, dim=1).view(\n            x.size(0), self.window_size, -1\n        )\n\n        decoder_out = self.decoder(h_end_rep)\n        out = self.fc(decoder_out)\n        #out = self.sigma1 * out\n        return out\n\n\nclass Forecasting_Model(nn.Module):\n    \"\"\"Forecasting model (fully-connected network)\n    :param in_dim: number of input features\n    :param hid_dim: hidden size of the FC network\n    :param out_dim: number of output features\n    :param n_layers: number of FC layers\n    :param dropout: dropout rate\n    \"\"\"\n\n    def __init__(self, in_dim, hid_dim, out_dim, n_layers, dropout):\n        super(Forecasting_Model, self).__init__()\n        layers = [nn.Linear(in_dim, hid_dim)]\n        for _ in range(n_layers - 1):\n            layers.append(nn.Linear(hid_dim, hid_dim))\n\n        layers.append(nn.Linear(hid_dim, out_dim))\n\n        self.layers = nn.ModuleList(layers)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n        #self.sigma2 = nn.Parameter(torch.tensor(0.5))\n\n    def forward(self, x):\n        for i in range(len(self.layers) - 1):\n            x = self.relu(self.layers[i](x))\n            x = self.dropout(x)\n            #x = self.sigma2 * x\n        return self.layers[-1](x)","metadata":{"id":"420yzfUkFqjF","execution":{"iopub.status.busy":"2023-04-30T08:34:09.579457Z","iopub.execute_input":"2023-04-30T08:34:09.579916Z","iopub.status.idle":"2023-04-30T08:34:09.665343Z","shell.execute_reply.started":"2023-04-30T08:34:09.579879Z","shell.execute_reply":"2023-04-30T08:34:09.664315Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class MTAD_GAT(nn.Module):\n\n    def __init__(\n        self,\n        n_features,\n        window_size,\n        out_dim,\n        kernel_size=7,\n        feat_gat_embed_dim=None,\n        time_gat_embed_dim=None,\n        use_gatv2=True,\n        gru_n_layers=1,\n        gru_hid_dim=150,\n        forecast_n_layers=1,\n        forecast_hid_dim=150,\n        recon_n_layers=1,\n        recon_hid_dim=150,\n        dropout=0.2,\n        alpha=0.2\n    ):\n        super(MTAD_GAT, self).__init__()\n\n        self.conv = ConvLayer(n_features, kernel_size)\n        self.dropout = dropout\n        self.feature_gat_0 = FeatureAttentionLayer0(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n#         self.feature_gat_0 = FeatureAttentionLayer0(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n        self.feature_gat_1 = FeatureAttentionLayer1(n_features, Window_1, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n        #self.feature_gat_2 = FeatureAttentionLayer0(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n        #self.feature_gat_3 = FeatureAttentionLayer1(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2= False , use_bias = False)\n        #self.sigmoid = nn.Sigmoid()\n        self.temporal_gat_0 = TemporalAttentionLayer(n_features, window_size, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n        self.temporal_gat_1 = TemporalAttentionLayer(n_features, Window_1, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n#         self.temporal_gat_1 = TemporalAttentionLayer(n_features, window_size, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n#         self.sigmoid = nn.Sigmoid()\n        \n        self.lstm = LSTMLayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n#         self.gru0 = GRULayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n        self.gru1 = GRULayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n       \n        self.forecasting_model_0 = Forecasting_Model(gru_hid_dim, forecast_hid_dim, out_dim, forecast_n_layers, dropout)\n        self.recon_model_0 = ReconstructionModel_0(window_size, gru_hid_dim, recon_hid_dim, out_dim, recon_n_layers, dropout)\n        self.forecasting_model_1 = Forecasting_Model(gru_hid_dim, forecast_hid_dim, out_dim, forecast_n_layers, dropout)\n        self.recon_model_1 = ReconstructionModel_1(window_size, gru_hid_dim, recon_hid_dim, out_dim, recon_n_layers, dropout)\n        \n        \n\n    def forward(self, x):\n        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n\n        x = self.conv(x)\n        x1 = x[:,Window_gap:Window,:]\n        h_feat_0 = self.feature_gat_0(x)\n        h_feat_0_x1 = self.feature_gat_1(x1)\n#         h_feat_1 = self.feature_gat_1(x)\n#         h_feat_2 = self.feature_gat_2(x)\n#         h_feat_3 = self.feature_gat_3(x)\n#         h_feat = self.sigmoid(h_feat_0 + h_feat_1)\n        h_temp = self.temporal_gat_0(x)\n        h_temp_x1 = self.temporal_gat_1(x1)\n#         h_temp_1 = self.temporal_gat_1(x)\n#         h_temp = self.sigmoid(h_temp_1 + h_temp_0)\n        h_cat = torch.cat([x, h_feat_0, h_temp], dim=2)  # (b, n, 3k)    (b, n, 4k)\n        h_cat_x1 = torch.cat([x1, h_feat_0_x1, h_temp_x1], dim=2)  # (b, n, 3k)\n        _, h_end = self.lstm(h_cat)\n        _, h_end_x1 = self.gru1(h_cat_x1)\n#         _, h_end = self.lstm(h_cat)\n        h_end = h_end.view(x.shape[0], -1)   # Hidden state for last timestamp\n        h_end_x1 = h_end_x1.view(x1.shape[0], -1)   # Hidden state for last timestamp\n\n        predictions = self.forecasting_model_0(h_end)\n        recons = self.recon_model_0(h_end)\n        predictions_x1 = self.forecasting_model_1(h_end_x1)\n        recons_x1 = self.recon_model_1(h_end_x1)\n#         return predictions, recons\n        return predictions, recons,predictions_x1,recons_x1","metadata":{"id":"PZ64Wi3uFwI4","execution":{"iopub.status.busy":"2023-04-30T08:34:09.666633Z","iopub.execute_input":"2023-04-30T08:34:09.667208Z","iopub.status.idle":"2023-04-30T08:34:09.685959Z","shell.execute_reply.started":"2023-04-30T08:34:09.667172Z","shell.execute_reply":"2023-04-30T08:34:09.684705Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = MTAD_GAT(n_features = number_features,  window_size = Window, out_dim = number_features, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)\n# model.to(device)\nmodel = model.to(device1)  # 将模型移动到第一个GPU设备上\nmodel = DataParallel(model, device_ids=[0, 1])  # 将模型封装为DataParallel模型，并指定使用两个GPU设备\nprint(model)","metadata":{"id":"YX0925OOFzkS","execution":{"iopub.status.busy":"2023-04-30T08:34:09.687517Z","iopub.execute_input":"2023-04-30T08:34:09.687871Z","iopub.status.idle":"2023-04-30T08:34:14.321478Z","shell.execute_reply.started":"2023-04-30T08:34:09.687835Z","shell.execute_reply":"2023-04-30T08:34:14.320312Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"DataParallel(\n  (module): MTAD_GAT(\n    (conv): ConvLayer(\n      (padding): ConstantPad1d(padding=(3, 3), value=0.0)\n      (conv): Conv1d(27, 27, kernel_size=(7,), stride=(1,))\n      (relu): ReLU()\n    )\n    (feature_gat_0): FeatureAttentionLayer0(\n      (lin): Linear(in_features=200, out_features=512, bias=True)\n      (leakyrelu): LeakyReLU(negative_slope=0.2)\n      (sigmoid): Sigmoid()\n    )\n    (feature_gat_1): FeatureAttentionLayer1(\n      (lin): Linear(in_features=160, out_features=512, bias=True)\n      (leakyrelu): LeakyReLU(negative_slope=0.2)\n      (sigmoid): Sigmoid()\n    )\n    (temporal_gat_0): TemporalAttentionLayer(\n      (lin): Linear(in_features=54, out_features=128, bias=True)\n      (leakyrelu): LeakyReLU(negative_slope=0.2)\n      (sigmoid): Sigmoid()\n    )\n    (temporal_gat_1): TemporalAttentionLayer(\n      (lin): Linear(in_features=54, out_features=128, bias=True)\n      (leakyrelu): LeakyReLU(negative_slope=0.2)\n      (sigmoid): Sigmoid()\n    )\n    (lstm): LSTMLayer(\n      (lstm): LSTM(81, 150, batch_first=True)\n    )\n    (gru1): GRULayer(\n      (gru): GRU(81, 150, batch_first=True)\n    )\n    (forecasting_model_0): Forecasting_Model(\n      (layers): ModuleList(\n        (0): Linear(in_features=150, out_features=150, bias=True)\n        (1): Linear(in_features=150, out_features=27, bias=True)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n      (relu): ReLU()\n    )\n    (recon_model_0): ReconstructionModel_0(\n      (decoder): LSTMDecoder(\n        (lstm): LSTM(150, 150, batch_first=True)\n      )\n      (fc): Linear(in_features=150, out_features=27, bias=True)\n    )\n    (forecasting_model_1): Forecasting_Model(\n      (layers): ModuleList(\n        (0): Linear(in_features=150, out_features=150, bias=True)\n        (1): Linear(in_features=150, out_features=27, bias=True)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n      (relu): ReLU()\n    )\n    (recon_model_1): ReconstructionModel_1(\n      (decoder): RNNDecoder(\n        (rnn): GRU(150, 150, batch_first=True)\n      )\n      (fc): Linear(in_features=150, out_features=27, bias=True)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"eg_out = model(eg[0].float().to(device))\neg_out[0].size(), eg_out[1].size()","metadata":{"id":"gP66AqENF6A5","outputId":"0be0a1d1-8441-4dd7-acb0-e892fe69b59c","execution":{"iopub.status.busy":"2023-04-30T08:34:14.323110Z","iopub.execute_input":"2023-04-30T08:34:14.323482Z","iopub.status.idle":"2023-04-30T08:34:21.573080Z","shell.execute_reply.started":"2023-04-30T08:34:14.323444Z","shell.execute_reply":"2023-04-30T08:34:21.571967Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:775: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:968.)\n  self.dropout, self.training, self.bidirectional, self.batch_first)\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:956: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:968.)\n  self.dropout, self.training, self.bidirectional, self.batch_first)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(torch.Size([256, 27]), torch.Size([256, 100, 27]))"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\nforecast_criterion = nn.MSELoss()\nrecon_criterion = nn.MSELoss()\nKL_criterion = torch.nn.KLDivLoss(reduction = 'batchmean')\nlen(train_dl), len(val_dl)","metadata":{"id":"s_uLWHVUF8Dw","outputId":"323a92a6-e75c-44ed-98a1-72130cc4ed6e","execution":{"iopub.status.busy":"2023-04-30T08:34:21.574778Z","iopub.execute_input":"2023-04-30T08:34:21.575384Z","iopub.status.idle":"2023-04-30T08:34:21.584587Z","shell.execute_reply.started":"2023-04-30T08:34:21.575339Z","shell.execute_reply":"2023-04-30T08:34:21.583383Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(5, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# def JS_div(p, q, get_softmax=True):\n#     \"\"\"\n#     Function that measures JS divergence between target and output logits:\n#     \"\"\"\n#     KLDivLoss = nn.KLDivLoss(reduction='batchmean')\n#     if get_softmax:\n#         p_output = F.softmax(p)\n#         q_output = F.softmax(q)\n#     log_mean_output = ((p + q )/2).log()\n#     return (KLDivLoss(log_mean_output, p) + KLDivLoss(log_mean_output, q))/2","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:34:21.586334Z","iopub.execute_input":"2023-04-30T08:34:21.586715Z","iopub.status.idle":"2023-04-30T08:34:21.595362Z","shell.execute_reply.started":"2023-04-30T08:34:21.586677Z","shell.execute_reply":"2023-04-30T08:34:21.594061Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!mkdir model_checkpoints","metadata":{"id":"G0WwiKeZGAX7","outputId":"4553ac92-1811-4f80-b98a-0aeb631efc27","execution":{"iopub.status.busy":"2023-04-30T08:34:21.596865Z","iopub.execute_input":"2023-04-30T08:34:21.597780Z","iopub.status.idle":"2023-04-30T08:34:22.649950Z","shell.execute_reply.started":"2023-04-30T08:34:21.597743Z","shell.execute_reply":"2023-04-30T08:34:22.648380Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"Best_Valid_loss = 999999\nBest_Epoch = -1\ny1 = []\ny2 = []\ny3 = []\ny4 = []\nfor epoch in range(EPOCHS):\n    model.train()\n    forecast_b_losses = []\n    recon_b_losses = []\n    forecast_b_losses_1 = []\n    recon_b_losses_1 = []\n\n    print(\"Epoch : \", epoch)\n    print(\"Training Started ... \")\n    \n    for batch_idx, batch in enumerate(train_dl):\n        x = batch[0].to(device1).float()\n        y = batch[1].to(device1).float()\n        optimizer.zero_grad()\n\n        preds, recons ,preds_1, recons_1 = model(x)\n        \n        #KL散度\n        KL_pre = KL_criterion(preds.softmax(dim=-1).log(),preds_1.softmax(dim=-1))\n        KL_recon = KL_criterion(recons.softmax(dim=-1).log(),recons_1.softmax(dim=-1))\n        #JS散度\n        \n        \n        forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1), preds))\n        recon_loss = torch.sqrt(recon_criterion(x, recons))\n        forecast_loss_1 = torch.sqrt(forecast_criterion(y.squeeze(1), preds_1))\n        recon_loss_1 = torch.sqrt(recon_criterion(x, recons_1))\n        loss = forecast_loss + recon_loss + forecast_loss_1 + recon_loss_1 + KL_pre + KL_recon\n\n        loss.backward()\n        optimizer.step()\n\n        forecast_b_losses.append(forecast_loss.item())\n        recon_b_losses.append(recon_loss.item())\n        forecast_b_losses_1.append(forecast_loss_1.item())\n        recon_b_losses_1.append(recon_loss_1.item())\n        \n\n    forecast_b_losses = np.array(forecast_b_losses)\n    recon_b_losses = np.array(recon_b_losses)\n    forecast_b_losses_1 = np.array(forecast_b_losses_1)\n    recon_b_losses_1 = np.array(recon_b_losses_1)\n\n    forecast_epoch_loss = np.sqrt((forecast_b_losses ** 2).mean())\n    recon_epoch_loss = np.sqrt((recon_b_losses ** 2).mean())\n    y1.append(forecast_epoch_loss)\n    y2.append(recon_epoch_loss)\n\n    total_epoch_loss = forecast_epoch_loss + recon_epoch_loss\n    \n    print('Forecasting Loss : ', forecast_epoch_loss,'Reconstruction Loss : ', recon_epoch_loss)\n    \n    \n    forecast_b_losses_eval = []\n    recon_b_losses_eval = []\n    \n    print(\"Validation Started ... \")\n    \n    model.eval()\n    with torch.no_grad():\n        for batch_idx, batch in enumerate(val_dl):\n            x = batch[0].to(device).float()\n            y = batch[1].to(device).float()\n\n            preds, recons ,preds_1, recons_1 = model(x)\n\n            forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1), preds))\n            recon_loss = torch.sqrt(recon_criterion(x, recons))\n            loss = forecast_loss + recon_loss\n\n            forecast_b_losses_eval.append(forecast_loss.item())\n            recon_b_losses_eval.append(recon_loss.item())\n\n    forecast_b_losses_eval = np.array(forecast_b_losses_eval)\n    recon_b_losses_eval = np.array(recon_b_losses_eval)\n\n    forecast_epoch_loss_eval = np.sqrt((forecast_b_losses_eval ** 2).mean())\n    recon_epoch_loss_eval = np.sqrt((recon_b_losses_eval ** 2).mean())\n    y3.append(forecast_epoch_loss_eval)\n    y4.append(recon_epoch_loss_eval)\n    total_epoch_loss_eval = forecast_epoch_loss_eval + recon_epoch_loss_eval\n    \n    print('Forecasting Loss : ', forecast_epoch_loss_eval,'Reconstruction Loss : ', recon_epoch_loss_eval)\n\n    if total_epoch_loss_eval < Best_Valid_loss:\n        Best_Valid_loss = total_epoch_loss_eval\n        Best_Epoch = epoch\n        \n        ckpt = {\n            'Epoch' : epoch,\n            'Model' : model.state_dict(),\n            'Optimizer' : optimizer.state_dict(),\n            'Train_Forecast_loss' : forecast_epoch_loss,\n            'Train_Recon_loss' : recon_epoch_loss,\n            'Eval_Forecast_loss' : forecast_epoch_loss_eval,\n            'Eval_Recon_loss' : recon_epoch_loss_eval\n        }\n        \n        torch.save(ckpt, os.path.join('model_checkpoints', str(epoch) + '.pt'))","metadata":{"id":"PL_CjIqDGD4A","outputId":"5150a107-f44a-49a5-bbb5-0e74dc239b21","execution":{"iopub.status.busy":"2023-04-30T08:34:22.652769Z","iopub.execute_input":"2023-04-30T08:34:22.653765Z","iopub.status.idle":"2023-04-30T08:36:06.676161Z","shell.execute_reply.started":"2023-04-30T08:34:22.653708Z","shell.execute_reply":"2023-04-30T08:36:06.674903Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch :  0\nTraining Started ... \nForecasting Loss :  0.8110198445755361 Reconstruction Loss :  0.8578498820086993\nValidation Started ... \nForecasting Loss :  0.7253165222558577 Reconstruction Loss :  0.8419843446753466\nEpoch :  1\nTraining Started ... \nForecasting Loss :  0.6353827210730942 Reconstruction Loss :  0.8449949194779145\nValidation Started ... \nForecasting Loss :  0.4897583801425588 Reconstruction Loss :  0.8267706721958451\nEpoch :  2\nTraining Started ... \nForecasting Loss :  0.5043070581963487 Reconstruction Loss :  0.8234972820461365\nValidation Started ... \nForecasting Loss :  0.47206452896862416 Reconstruction Loss :  0.8007000734408448\nEpoch :  3\nTraining Started ... \nForecasting Loss :  0.4853754046109389 Reconstruction Loss :  0.7906604717911211\nValidation Started ... \nForecasting Loss :  0.4747689227885255 Reconstruction Loss :  0.7414406380667028\nEpoch :  4\nTraining Started ... \nForecasting Loss :  0.4847688030199849 Reconstruction Loss :  0.7010862844420453\nValidation Started ... \nForecasting Loss :  0.4550801649014733 Reconstruction Loss :  0.573787024887847\nEpoch :  5\nTraining Started ... \nForecasting Loss :  0.48055117410178233 Reconstruction Loss :  0.5778972892403292\nValidation Started ... \nForecasting Loss :  0.4670622379279719 Reconstruction Loss :  0.5747963775261385\nEpoch :  6\nTraining Started ... \nForecasting Loss :  0.4752771286834572 Reconstruction Loss :  0.5635918379116169\nValidation Started ... \nForecasting Loss :  0.4680217239697866 Reconstruction Loss :  0.5393873521080371\nEpoch :  7\nTraining Started ... \nForecasting Loss :  0.4750246946186095 Reconstruction Loss :  0.5561290819260661\nValidation Started ... \nForecasting Loss :  0.4785710835718761 Reconstruction Loss :  0.5367770310263483\nEpoch :  8\nTraining Started ... \nForecasting Loss :  0.4726281885979038 Reconstruction Loss :  0.5400756990051231\nValidation Started ... \nForecasting Loss :  0.46585340452717977 Reconstruction Loss :  0.5179786503691878\nEpoch :  9\nTraining Started ... \nForecasting Loss :  0.4711615339794626 Reconstruction Loss :  0.5268324722412714\nValidation Started ... \nForecasting Loss :  0.4637285251985421 Reconstruction Loss :  0.4998586552154231\nEpoch :  10\nTraining Started ... \nForecasting Loss :  0.47319353796661623 Reconstruction Loss :  0.5158050348674154\nValidation Started ... \nForecasting Loss :  0.47203456685195183 Reconstruction Loss :  0.4940120927039279\nEpoch :  11\nTraining Started ... \nForecasting Loss :  0.4705937463994184 Reconstruction Loss :  0.504150880030378\nValidation Started ... \nForecasting Loss :  0.47100654842527057 Reconstruction Loss :  0.4807754218525601\nEpoch :  12\nTraining Started ... \nForecasting Loss :  0.4682068443888855 Reconstruction Loss :  0.4966953118286866\nValidation Started ... \nForecasting Loss :  0.4591109586672899 Reconstruction Loss :  0.4761310465234214\nEpoch :  13\nTraining Started ... \nForecasting Loss :  0.4672393219947493 Reconstruction Loss :  0.49219233825134046\nValidation Started ... \nForecasting Loss :  0.4551246102798458 Reconstruction Loss :  0.4673830424030949\nEpoch :  14\nTraining Started ... \nForecasting Loss :  0.4670797339454837 Reconstruction Loss :  0.49187862229844426\nValidation Started ... \nForecasting Loss :  0.4492510805196513 Reconstruction Loss :  0.4710272745277259\nEpoch :  15\nTraining Started ... \nForecasting Loss :  0.4638505121129924 Reconstruction Loss :  0.4885151673291432\nValidation Started ... \nForecasting Loss :  0.46497130420499466 Reconstruction Loss :  0.4767217465831191\nEpoch :  16\nTraining Started ... \nForecasting Loss :  0.46055091711882723 Reconstruction Loss :  0.4890261241908188\nValidation Started ... \nForecasting Loss :  0.4659398889039242 Reconstruction Loss :  0.46983599179047003\nEpoch :  17\nTraining Started ... \nForecasting Loss :  0.45200972706902215 Reconstruction Loss :  0.4873225217946301\nValidation Started ... \nForecasting Loss :  0.44078908676355233 Reconstruction Loss :  0.46548433822949575\nEpoch :  18\nTraining Started ... \nForecasting Loss :  0.44161420843245225 Reconstruction Loss :  0.48559559714973866\nValidation Started ... \nForecasting Loss :  0.41479476887084243 Reconstruction Loss :  0.46870824849383014\nEpoch :  19\nTraining Started ... \nForecasting Loss :  0.42842799105350077 Reconstruction Loss :  0.48695714424076153\nValidation Started ... \nForecasting Loss :  0.4137576443950474 Reconstruction Loss :  0.4825587471156383\nEpoch :  20\nTraining Started ... \nForecasting Loss :  0.41229639278417607 Reconstruction Loss :  0.48535762683421035\nValidation Started ... \nForecasting Loss :  0.3923805959256066 Reconstruction Loss :  0.47012789486724643\nEpoch :  21\nTraining Started ... \nForecasting Loss :  0.4017538775370004 Reconstruction Loss :  0.4867681618065755\nValidation Started ... \nForecasting Loss :  0.377435629278431 Reconstruction Loss :  0.4671325960793443\nEpoch :  22\nTraining Started ... \nForecasting Loss :  0.39096039542639827 Reconstruction Loss :  0.48446487779418906\nValidation Started ... \nForecasting Loss :  0.3735195743382546 Reconstruction Loss :  0.4779132928154329\nEpoch :  23\nTraining Started ... \nForecasting Loss :  0.3851520836850737 Reconstruction Loss :  0.48584335854895294\nValidation Started ... \nForecasting Loss :  0.3726553780826772 Reconstruction Loss :  0.48424868626934736\nEpoch :  24\nTraining Started ... \nForecasting Loss :  0.37842362538187446 Reconstruction Loss :  0.48584140162771505\nValidation Started ... \nForecasting Loss :  0.35840711958779553 Reconstruction Loss :  0.45831154175182265\nEpoch :  25\nTraining Started ... \nForecasting Loss :  0.37121862606186723 Reconstruction Loss :  0.4854501799762191\nValidation Started ... \nForecasting Loss :  0.35616541796365064 Reconstruction Loss :  0.4587581399875153\nEpoch :  26\nTraining Started ... \nForecasting Loss :  0.3678476906199349 Reconstruction Loss :  0.4851038094925394\nValidation Started ... \nForecasting Loss :  0.34638991730400287 Reconstruction Loss :  0.46741661399587114\nEpoch :  27\nTraining Started ... \nForecasting Loss :  0.3619021390554852 Reconstruction Loss :  0.48522071735472166\nValidation Started ... \nForecasting Loss :  0.349376551085354 Reconstruction Loss :  0.4707211071780072\nEpoch :  28\nTraining Started ... \nForecasting Loss :  0.3572260150685938 Reconstruction Loss :  0.48731794564050007\nValidation Started ... \nForecasting Loss :  0.34957469801594276 Reconstruction Loss :  0.4689811661777663\nEpoch :  29\nTraining Started ... \nForecasting Loss :  0.35228051320319864 Reconstruction Loss :  0.4855833212723913\nValidation Started ... \nForecasting Loss :  0.34079079234835985 Reconstruction Loss :  0.478095203557042\nEpoch :  30\nTraining Started ... \nForecasting Loss :  0.3497779998719697 Reconstruction Loss :  0.4843090518771526\nValidation Started ... \nForecasting Loss :  0.3529811239995376 Reconstruction Loss :  0.45691140299136984\nEpoch :  31\nTraining Started ... \nForecasting Loss :  0.34740391008818367 Reconstruction Loss :  0.4848160888524319\nValidation Started ... \nForecasting Loss :  0.3279485904396107 Reconstruction Loss :  0.46807222299884954\nEpoch :  32\nTraining Started ... \nForecasting Loss :  0.3423582735156779 Reconstruction Loss :  0.48461299019480536\nValidation Started ... \nForecasting Loss :  0.32145387693728034 Reconstruction Loss :  0.4675943109055006\nEpoch :  33\nTraining Started ... \nForecasting Loss :  0.33957789123051596 Reconstruction Loss :  0.48402971473578643\nValidation Started ... \nForecasting Loss :  0.324906312211517 Reconstruction Loss :  0.4681337943739494\nEpoch :  34\nTraining Started ... \nForecasting Loss :  0.3348873442550326 Reconstruction Loss :  0.4845443766931184\nValidation Started ... \nForecasting Loss :  0.32771026850331253 Reconstruction Loss :  0.46818371665384867\nEpoch :  35\nTraining Started ... \nForecasting Loss :  0.3315396601013298 Reconstruction Loss :  0.4857167834887481\nValidation Started ... \nForecasting Loss :  0.315525206008562 Reconstruction Loss :  0.46108841506957887\nEpoch :  36\nTraining Started ... \nForecasting Loss :  0.33126722837396105 Reconstruction Loss :  0.483518171091398\nValidation Started ... \nForecasting Loss :  0.317370051783467 Reconstruction Loss :  0.46038585684488076\nEpoch :  37\nTraining Started ... \nForecasting Loss :  0.3271698134073794 Reconstruction Loss :  0.483864939261594\nValidation Started ... \nForecasting Loss :  0.3101192634582092 Reconstruction Loss :  0.4574445215759185\nEpoch :  38\nTraining Started ... \nForecasting Loss :  0.32561146221165244 Reconstruction Loss :  0.4839332155975348\nValidation Started ... \nForecasting Loss :  0.31317790031354753 Reconstruction Loss :  0.46843824870160994\nEpoch :  39\nTraining Started ... \nForecasting Loss :  0.32207165869071047 Reconstruction Loss :  0.48397630014431126\nValidation Started ... \nForecasting Loss :  0.3070825373344314 Reconstruction Loss :  0.46655052448738416\nEpoch :  40\nTraining Started ... \nForecasting Loss :  0.31937062351558393 Reconstruction Loss :  0.4843900073326942\nValidation Started ... \nForecasting Loss :  0.30691592194825057 Reconstruction Loss :  0.46164773013104643\nEpoch :  41\nTraining Started ... \nForecasting Loss :  0.3205351697771096 Reconstruction Loss :  0.4832566284623268\nValidation Started ... \nForecasting Loss :  0.3196418271945803 Reconstruction Loss :  0.475984401780595\nEpoch :  42\nTraining Started ... \nForecasting Loss :  0.3150200236327812 Reconstruction Loss :  0.4837246113025916\nValidation Started ... \nForecasting Loss :  0.29114911670309696 Reconstruction Loss :  0.46354817945940796\nEpoch :  43\nTraining Started ... \nForecasting Loss :  0.3139601247540732 Reconstruction Loss :  0.48268851770084703\nValidation Started ... \nForecasting Loss :  0.3063018332278827 Reconstruction Loss :  0.4603572555476321\nEpoch :  44\nTraining Started ... \nForecasting Loss :  0.31052613207945245 Reconstruction Loss :  0.4830722540427887\nValidation Started ... \nForecasting Loss :  0.3021157145732661 Reconstruction Loss :  0.4798516752722826\nEpoch :  45\nTraining Started ... \nForecasting Loss :  0.31176212192749936 Reconstruction Loss :  0.4837917449261255\nValidation Started ... \nForecasting Loss :  0.303171066531132 Reconstruction Loss :  0.4564565586406002\nEpoch :  46\nTraining Started ... \nForecasting Loss :  0.3082578153780748 Reconstruction Loss :  0.48202658654702224\nValidation Started ... \nForecasting Loss :  0.2902439677245592 Reconstruction Loss :  0.46312049685997153\nEpoch :  47\nTraining Started ... \nForecasting Loss :  0.30490241757730996 Reconstruction Loss :  0.48266829521098714\nValidation Started ... \nForecasting Loss :  0.29257756560160536 Reconstruction Loss :  0.47293507096369564\nEpoch :  48\nTraining Started ... \nForecasting Loss :  0.3019801532147624 Reconstruction Loss :  0.4821985380343251\nValidation Started ... \nForecasting Loss :  0.3103920731957372 Reconstruction Loss :  0.47050508725368845\nEpoch :  49\nTraining Started ... \nForecasting Loss :  0.3020972537040869 Reconstruction Loss :  0.4800458336110366\nValidation Started ... \nForecasting Loss :  0.2814581982979476 Reconstruction Loss :  0.4648032444547759\nEpoch :  50\nTraining Started ... \nForecasting Loss :  0.301367264558168 Reconstruction Loss :  0.4809228054259496\nValidation Started ... \nForecasting Loss :  0.2799693454030785 Reconstruction Loss :  0.46045584681180696\nEpoch :  51\nTraining Started ... \nForecasting Loss :  0.29724708494661023 Reconstruction Loss :  0.48048574077812173\nValidation Started ... \nForecasting Loss :  0.2820254196159814 Reconstruction Loss :  0.46101122244603504\nEpoch :  52\nTraining Started ... \nForecasting Loss :  0.29472922060492507 Reconstruction Loss :  0.47922972819083715\nValidation Started ... \nForecasting Loss :  0.2705652010546611 Reconstruction Loss :  0.4457178244759343\nEpoch :  53\nTraining Started ... \nForecasting Loss :  0.2942733747431287 Reconstruction Loss :  0.4789848920795856\nValidation Started ... \nForecasting Loss :  0.2708007937144525 Reconstruction Loss :  0.4578596160390736\nEpoch :  54\nTraining Started ... \nForecasting Loss :  0.2912674583376615 Reconstruction Loss :  0.47787312142063826\nValidation Started ... \nForecasting Loss :  0.28042537899621345 Reconstruction Loss :  0.46488020185014794\nEpoch :  55\nTraining Started ... \nForecasting Loss :  0.29048965123819087 Reconstruction Loss :  0.4758632813781383\nValidation Started ... \nForecasting Loss :  0.2787981014349555 Reconstruction Loss :  0.46578513049450276\nEpoch :  56\nTraining Started ... \nForecasting Loss :  0.28780154069957037 Reconstruction Loss :  0.4729169414376514\nValidation Started ... \nForecasting Loss :  0.26834122819585904 Reconstruction Loss :  0.45185440215475275\nEpoch :  57\nTraining Started ... \nForecasting Loss :  0.2871826275433896 Reconstruction Loss :  0.4689937654939445\nValidation Started ... \nForecasting Loss :  0.2745941692420458 Reconstruction Loss :  0.4416470713534619\nEpoch :  58\nTraining Started ... \nForecasting Loss :  0.2845604559335076 Reconstruction Loss :  0.4640412964829144\nValidation Started ... \nForecasting Loss :  0.2906941232801859 Reconstruction Loss :  0.45031144515693466\nEpoch :  59\nTraining Started ... \nForecasting Loss :  0.2859362631745064 Reconstruction Loss :  0.46158017007697455\nValidation Started ... \nForecasting Loss :  0.267212240474473 Reconstruction Loss :  0.4318227181529494\nEpoch :  60\nTraining Started ... \nForecasting Loss :  0.28293629360155476 Reconstruction Loss :  0.45813706129932863\nValidation Started ... \nForecasting Loss :  0.26777738880103574 Reconstruction Loss :  0.4375918107695955\nEpoch :  61\nTraining Started ... \nForecasting Loss :  0.2820564892575093 Reconstruction Loss :  0.4562494198419914\nValidation Started ... \nForecasting Loss :  0.2730562515485478 Reconstruction Loss :  0.4442056723505851\nEpoch :  62\nTraining Started ... \nForecasting Loss :  0.2798894037183503 Reconstruction Loss :  0.4545148775180123\nValidation Started ... \nForecasting Loss :  0.25511609130100865 Reconstruction Loss :  0.4412447481178912\nEpoch :  63\nTraining Started ... \nForecasting Loss :  0.27724670480800434 Reconstruction Loss :  0.4521937992628263\nValidation Started ... \nForecasting Loss :  0.25915541835343897 Reconstruction Loss :  0.43496799080542164\nEpoch :  64\nTraining Started ... \nForecasting Loss :  0.2757103967508149 Reconstruction Loss :  0.45088927109507226\nValidation Started ... \nForecasting Loss :  0.2517424560629368 Reconstruction Loss :  0.4335157585133287\nEpoch :  65\nTraining Started ... \nForecasting Loss :  0.2739212460654146 Reconstruction Loss :  0.44953383471680985\nValidation Started ... \nForecasting Loss :  0.24762526971519447 Reconstruction Loss :  0.42799591695999595\nEpoch :  66\nTraining Started ... \nForecasting Loss :  0.2726239604696248 Reconstruction Loss :  0.4488220517852596\nValidation Started ... \nForecasting Loss :  0.2618391794888409 Reconstruction Loss :  0.44011818680992526\nEpoch :  67\nTraining Started ... \nForecasting Loss :  0.2709551874602676 Reconstruction Loss :  0.44927722445618223\nValidation Started ... \nForecasting Loss :  0.2530762709655508 Reconstruction Loss :  0.4274304584367205\nEpoch :  68\nTraining Started ... \nForecasting Loss :  0.2722834839370818 Reconstruction Loss :  0.44819585490354047\nValidation Started ... \nForecasting Loss :  0.2441359964986565 Reconstruction Loss :  0.42809280201528815\nEpoch :  69\nTraining Started ... \nForecasting Loss :  0.2706603661712201 Reconstruction Loss :  0.4478122501471301\nValidation Started ... \nForecasting Loss :  0.28011846885637814 Reconstruction Loss :  0.43549690262511137\nEpoch :  70\nTraining Started ... \nForecasting Loss :  0.27069518752674154 Reconstruction Loss :  0.4473694995584207\nValidation Started ... \nForecasting Loss :  0.2577935072864619 Reconstruction Loss :  0.4452832736473212\nEpoch :  71\nTraining Started ... \nForecasting Loss :  0.26726271281425446 Reconstruction Loss :  0.44729055052097494\nValidation Started ... \nForecasting Loss :  0.2634041683536603 Reconstruction Loss :  0.44331840072105055\nEpoch :  72\nTraining Started ... \nForecasting Loss :  0.2663114871630525 Reconstruction Loss :  0.44754207490997255\nValidation Started ... \nForecasting Loss :  0.2586192554620449 Reconstruction Loss :  0.44839857601387917\nEpoch :  73\nTraining Started ... \nForecasting Loss :  0.26635339296070726 Reconstruction Loss :  0.4474917426257915\nValidation Started ... \nForecasting Loss :  0.2564680689534847 Reconstruction Loss :  0.4299882334930821\nEpoch :  74\nTraining Started ... \nForecasting Loss :  0.2650463678794298 Reconstruction Loss :  0.4474825299846921\nValidation Started ... \nForecasting Loss :  0.24003497247581068 Reconstruction Loss :  0.4328304061786285\nEpoch :  75\nTraining Started ... \nForecasting Loss :  0.2658779204751208 Reconstruction Loss :  0.4474617252475774\nValidation Started ... \nForecasting Loss :  0.2413014112432423 Reconstruction Loss :  0.41959628301410523\nEpoch :  76\nTraining Started ... \nForecasting Loss :  0.26302689421436365 Reconstruction Loss :  0.44576003290961624\nValidation Started ... \nForecasting Loss :  0.248075547137698 Reconstruction Loss :  0.4325963080330272\nEpoch :  77\nTraining Started ... \nForecasting Loss :  0.2628790998968633 Reconstruction Loss :  0.4468250005064117\nValidation Started ... \nForecasting Loss :  0.2544235857878698 Reconstruction Loss :  0.4335755500316072\nEpoch :  78\nTraining Started ... \nForecasting Loss :  0.2594648667455143 Reconstruction Loss :  0.44614029524513993\nValidation Started ... \nForecasting Loss :  0.26805375438088996 Reconstruction Loss :  0.4277832204776465\nEpoch :  79\nTraining Started ... \nForecasting Loss :  0.26159198119339666 Reconstruction Loss :  0.4447265971584184\nValidation Started ... \nForecasting Loss :  0.2466387979536549 Reconstruction Loss :  0.43895704063663915\nEpoch :  80\nTraining Started ... \nForecasting Loss :  0.26170933575270455 Reconstruction Loss :  0.4474107492840805\nValidation Started ... \nForecasting Loss :  0.2539402361015235 Reconstruction Loss :  0.44417310255432624\nEpoch :  81\nTraining Started ... \nForecasting Loss :  0.25668530764886044 Reconstruction Loss :  0.4455148391228749\nValidation Started ... \nForecasting Loss :  0.24181687521033343 Reconstruction Loss :  0.4346659047571727\nEpoch :  82\nTraining Started ... \nForecasting Loss :  0.2586760547457753 Reconstruction Loss :  0.4461731035595785\nValidation Started ... \nForecasting Loss :  0.2473255464989674 Reconstruction Loss :  0.4268548347148653\nEpoch :  83\nTraining Started ... \nForecasting Loss :  0.2578102098182201 Reconstruction Loss :  0.4461127799712637\nValidation Started ... \nForecasting Loss :  0.2532191051495866 Reconstruction Loss :  0.42940786715130175\nEpoch :  84\nTraining Started ... \nForecasting Loss :  0.2566390189427224 Reconstruction Loss :  0.4441752843715289\nValidation Started ... \nForecasting Loss :  0.2467575467031508 Reconstruction Loss :  0.4262787418889962\nEpoch :  85\nTraining Started ... \nForecasting Loss :  0.2560233159173264 Reconstruction Loss :  0.44511084061848966\nValidation Started ... \nForecasting Loss :  0.24312787338099637 Reconstruction Loss :  0.4250152442253458\nEpoch :  86\nTraining Started ... \nForecasting Loss :  0.25614930790773466 Reconstruction Loss :  0.4451455623915997\nValidation Started ... \nForecasting Loss :  0.23983382819877963 Reconstruction Loss :  0.42625547777082196\nEpoch :  87\nTraining Started ... \nForecasting Loss :  0.25762306133168505 Reconstruction Loss :  0.44475980506857377\nValidation Started ... \nForecasting Loss :  0.24965886684060692 Reconstruction Loss :  0.4212147254192179\nEpoch :  88\nTraining Started ... \nForecasting Loss :  0.2563661026876467 Reconstruction Loss :  0.44582417965779075\nValidation Started ... \nForecasting Loss :  0.23977570946202814 Reconstruction Loss :  0.4248147639100492\nEpoch :  89\nTraining Started ... \nForecasting Loss :  0.25797638157196195 Reconstruction Loss :  0.4455068806242717\nValidation Started ... \nForecasting Loss :  0.2598170203436422 Reconstruction Loss :  0.43090549683972795\nEpoch :  90\nTraining Started ... \nForecasting Loss :  0.252603011217969 Reconstruction Loss :  0.4447335719480461\nValidation Started ... \nForecasting Loss :  0.23179963145039353 Reconstruction Loss :  0.4129873837668632\nEpoch :  91\nTraining Started ... \nForecasting Loss :  0.25295247708851265 Reconstruction Loss :  0.4433761829240315\nValidation Started ... \nForecasting Loss :  0.23515829201494096 Reconstruction Loss :  0.42895243394231064\nEpoch :  92\nTraining Started ... \nForecasting Loss :  0.25389554157356653 Reconstruction Loss :  0.4449709461017407\nValidation Started ... \nForecasting Loss :  0.23918314352024644 Reconstruction Loss :  0.42161390275491056\nEpoch :  93\nTraining Started ... \nForecasting Loss :  0.25286103180736014 Reconstruction Loss :  0.44365536597103666\nValidation Started ... \nForecasting Loss :  0.25935612335268415 Reconstruction Loss :  0.4249962177201061\nEpoch :  94\nTraining Started ... \nForecasting Loss :  0.25148471377943593 Reconstruction Loss :  0.4450962407665683\nValidation Started ... \nForecasting Loss :  0.24779536011602088 Reconstruction Loss :  0.42234773477455356\nEpoch :  95\nTraining Started ... \nForecasting Loss :  0.2530199665211746 Reconstruction Loss :  0.44362050692879323\nValidation Started ... \nForecasting Loss :  0.2415028873640829 Reconstruction Loss :  0.43730522307665426\nEpoch :  96\nTraining Started ... \nForecasting Loss :  0.24912019184710865 Reconstruction Loss :  0.4432539250087337\nValidation Started ... \nForecasting Loss :  0.24193672017130957 Reconstruction Loss :  0.4168614245864972\nEpoch :  97\nTraining Started ... \nForecasting Loss :  0.24987685146863609 Reconstruction Loss :  0.4436775153603058\nValidation Started ... \nForecasting Loss :  0.23064410976850083 Reconstruction Loss :  0.43162798889090487\nEpoch :  98\nTraining Started ... \nForecasting Loss :  0.24752289605812544 Reconstruction Loss :  0.4417719580107518\nValidation Started ... \nForecasting Loss :  0.23280373490545403 Reconstruction Loss :  0.4235513943138385\nEpoch :  99\nTraining Started ... \nForecasting Loss :  0.24935203462335095 Reconstruction Loss :  0.44257709989750926\nValidation Started ... \nForecasting Loss :  0.23201592265628776 Reconstruction Loss :  0.42500209183754695\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nx=range(0,EPOCHS)\n# plt.ylim((0, 1))\nplt.plot(x,y1,label='recon_losses',color='green')\nplt.plot(x,y2,label='forecast_losses',color='blue')\nplt.xlabel(f'EPOCH{EPOCHS}_WindowSIZE{Window}_windowgap{Window_gap}')\nplt.ylabel('train_Loss')\nplt.savefig(f'EPOCH{EPOCHS}_WindowSIZE{Window}_MSL_train_contrastive.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:06.678164Z","iopub.execute_input":"2023-04-30T08:36:06.678565Z","iopub.status.idle":"2023-04-30T08:36:06.958947Z","shell.execute_reply.started":"2023-04-30T08:36:06.678515Z","shell.execute_reply":"2023-04-30T08:36:06.957972Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nx=range(0,EPOCHS)\nplt.plot(x,y3,label='recon_losses',color='green')\nplt.plot(x,y4,label='forecast_losses',color='blue')\nplt.xlabel(f'EPOCH{EPOCHS}_WindowSIZE{Window}_windowgap{Window_gap}')\nplt.ylabel('eval_Loss')\nplt.savefig(f'EPOCH{EPOCHS}_WindowSIZE{Window}_MSL_eval_contrastive.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:53:23.912009Z","iopub.execute_input":"2023-04-30T08:53:23.913199Z","iopub.status.idle":"2023-04-30T08:53:24.182177Z","shell.execute_reply.started":"2023-04-30T08:53:23.913157Z","shell.execute_reply":"2023-04-30T08:53:24.181020Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"best_model = MTAD_GAT(n_features = number_features, window_size = Window, out_dim = number_features, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)\nbest_model=torch.nn.DataParallel(best_model,device_ids=[0,1]).cuda() \nbest_model.load_state_dict( torch.load( os.path.join( 'model_checkpoints', str(Best_Epoch) + '.pt' ) )['Model'] )\n# best_model.to(device1)\n# model = model.to(device1)  # 将模型移动到第一个GPU设备上\n# model = DataParallel(model, device_ids=[0, 1])  # 将模型封装为DataParallel模型，并指定使用两个GPU设备","metadata":{"id":"S1OXA9bNGODE","outputId":"3e1e3d6e-920f-445e-d557-c168428306a0","execution":{"iopub.status.busy":"2023-04-30T08:36:07.220478Z","iopub.execute_input":"2023-04-30T08:36:07.220856Z","iopub.status.idle":"2023-04-30T08:36:07.267993Z","shell.execute_reply.started":"2023-04-30T08:36:07.220819Z","shell.execute_reply":"2023-04-30T08:36:07.266881Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# mydata_test= pd.read_csv('/kaggle/input/train-test/test.csv')\n# # mydata_test= pd.read_csv('/kaggle/input/abnormal-data/abnormal_test.csv')\n# mydata_test = np.array(mydata_test)\n# mydata_test = mydata_test[:,0:9]\n# mydata_test.shape\n\n# smap_data_test = []\n# for smap_channel in smap_channels:\n#     tmp_data = np.load(os.path.join('data/test/', smap_channel + '.npy'))\n#     smap_data_test.extend(tmp_data)  \n# smap_data_test = np.array(smap_data_test)\n# print(\"Shape of Test DataSet : \", smap_data_test.shape)\n\n# mydata_test= pd.read_csv('/kaggle/input/train-test/test.csv')\nmydata_test= pd.read_csv('/kaggle/input/msl-data/msl_test.csv')\n\nmydata_test = np.array(mydata_test)\nmydata_test = mydata_test[:,0:27]\nmydata_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:07.269632Z","iopub.execute_input":"2023-04-30T08:36:07.270017Z","iopub.status.idle":"2023-04-30T08:36:07.300958Z","shell.execute_reply.started":"2023-04-30T08:36:07.269963Z","shell.execute_reply":"2023-04-30T08:36:07.299903Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(2049, 27)"},"metadata":{}}]},{"cell_type":"code","source":"my_data_test_norm, _ = normalize_data(mydata_test, scaler)\nmy_data_test_norm = mydata_test[:1000]\nmy_data_test_pt = torch.from_numpy(my_data_test_norm)\nmy_data_test_pt.size()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:07.306388Z","iopub.execute_input":"2023-04-30T08:36:07.306733Z","iopub.status.idle":"2023-04-30T08:36:07.320197Z","shell.execute_reply.started":"2023-04-30T08:36:07.306704Z","shell.execute_reply":"2023-04-30T08:36:07.319086Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Data normalized\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([1000, 27])"},"metadata":{}}]},{"cell_type":"code","source":"my_test_x_y = SlidingWindowDataset(my_data_test_pt, Window)\ntest_dl = torch.utils.data.DataLoader(my_test_x_y, batch_size=256, shuffle=False)\nprint(\"Number of Batches in Test Dataloader : \", len(test_dl))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:07.321806Z","iopub.execute_input":"2023-04-30T08:36:07.322227Z","iopub.status.idle":"2023-04-30T08:36:07.329245Z","shell.execute_reply.started":"2023-04-30T08:36:07.322190Z","shell.execute_reply":"2023-04-30T08:36:07.328040Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of Batches in Test Dataloader :  4\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# smap_data_test = []\n# for smap_channel in smap_channels:\n#     tmp_data = np.load(os.path.join('/kaggle/input/smapdatatest/test', smap_channel + '.npy'))\n#     smap_data_test.extend(tmp_data)\n    \n# smap_data_test = np.array(smap_data_test)\n# print(\"Shape of Test DataSet : \", smap_data_test.shape)","metadata":{"id":"OsZLixSJGSJC","outputId":"4b1966be-3166-4984-9c97-787dec80196a","execution":{"iopub.status.busy":"2023-04-30T08:36:07.330828Z","iopub.execute_input":"2023-04-30T08:36:07.331885Z","iopub.status.idle":"2023-04-30T08:36:07.339592Z","shell.execute_reply.started":"2023-04-30T08:36:07.331850Z","shell.execute_reply":"2023-04-30T08:36:07.338563Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# smap_data_test_norm, _ = normalize_data(smap_data_test, scaler)\n# smap_data_test_norm = smap_data_test_norm[:1000]\n# smap_data_test_pt = torch.from_numpy(smap_data_test_norm)\n# smap_data_test_pt.size()","metadata":{"id":"D35iN0JXGULL","outputId":"1ad49371-ccf1-4169-8960-7ea7589f5d36","execution":{"iopub.status.busy":"2023-04-30T08:36:07.342689Z","iopub.execute_input":"2023-04-30T08:36:07.343785Z","iopub.status.idle":"2023-04-30T08:36:07.350483Z","shell.execute_reply.started":"2023-04-30T08:36:07.343718Z","shell.execute_reply":"2023-04-30T08:36:07.349462Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# smap_test_x_y = SlidingWindowDataset(smap_data_test_pt, Window)\n# test_dl = torch.utils.data.DataLoader(smap_test_x_y, batch_size=256, shuffle=False)\n# print(\"Number of Batches in Test Dataloader : \", len(test_dl))","metadata":{"id":"vhUi8PaxGW3j","outputId":"cc6a63ab-a208-4457-95a2-e346c083ff58","execution":{"iopub.status.busy":"2023-04-30T08:36:07.351967Z","iopub.execute_input":"2023-04-30T08:36:07.352531Z","iopub.status.idle":"2023-04-30T08:36:07.360919Z","shell.execute_reply.started":"2023-04-30T08:36:07.352494Z","shell.execute_reply":"2023-04-30T08:36:07.359843Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.eval()\npreds = []\nrecons = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_dl):\n        x = batch[0].to(device).float()\n        y = batch[1].to(device).float()\n\n        y_hat, _ ,y_hat_1, _1 = model(x)\n\n        # Shifting input to include the observed value (y) when doing the reconstruction\n        recon_x = torch.cat((x[:, 1:, :], y), dim=1)\n        _, window_recon,_1, window_recon_1 = model(recon_x)\n\n        preds.append(y_hat.detach().cpu().numpy())\n        # Extract last reconstruction only\n        recons.append(window_recon[:, -1, :].detach().cpu().numpy())\n#         preds_1.append(y_hat_1.detach().cpu().numpy())\n#         # Extract last reconstruction only\n#         recons_1.append(window_recon_1[:, -1, :].detach().cpu().numpy())\n\n\n    preds = np.concatenate(preds, axis=0)\n    recons = np.concatenate(recons, axis=0)\n#     preds_1 = np.concatenate(preds_1, axis=0)\n#     recons_1 = np.concatenate(recons_1, axis=0)","metadata":{"id":"7kzhYPuvGZ51","outputId":"4220f5e2-cc18-48a9-d7ad-57fb1f521fff","execution":{"iopub.status.busy":"2023-04-30T08:36:07.362490Z","iopub.execute_input":"2023-04-30T08:36:07.362857Z","iopub.status.idle":"2023-04-30T08:36:08.026114Z","shell.execute_reply.started":"2023-04-30T08:36:07.362822Z","shell.execute_reply":"2023-04-30T08:36:08.025055Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0f38d88ca04e728e469c3d39774992"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:775: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:968.)\n  self.dropout, self.training, self.bidirectional, self.batch_first)\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:956: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:968.)\n  self.dropout, self.training, self.bidirectional, self.batch_first)\n","output_type":"stream"}]},{"cell_type":"code","source":"preds.shape, recons.shape\nscale_scores = True\n","metadata":{"id":"Qdyb2SzuGhX8","execution":{"iopub.status.busy":"2023-04-30T08:36:08.027244Z","iopub.execute_input":"2023-04-30T08:36:08.027875Z","iopub.status.idle":"2023-04-30T08:36:08.033452Z","shell.execute_reply.started":"2023-04-30T08:36:08.027830Z","shell.execute_reply":"2023-04-30T08:36:08.032239Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"preds_1.shape, recons_1.shape\nscale_scores = True","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:08.034809Z","iopub.execute_input":"2023-04-30T08:36:08.035661Z","iopub.status.idle":"2023-04-30T08:36:08.047508Z","shell.execute_reply.started":"2023-04-30T08:36:08.035620Z","shell.execute_reply":"2023-04-30T08:36:08.046438Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# actual = smap_data_test_norm[Window:]\nactual = my_data_test_norm[Window:]\n\nprint(actual.shape)\n\nanomaly_scores = np.zeros_like(actual)\ndf = pd.DataFrame()\nfor i in range(preds.shape[1]):\n    df[f\"Forecast_{i}\"] = preds[:, i]\n    df[f\"Recon_{i}\"] = recons[:, i]\n    df[f\"True_{i}\"] = actual[:, i]\n    a_score = np.sqrt((preds[:, i] - actual[:, i]) ** 2) + np.sqrt(\n        (recons[:, i] - actual[:, i]) ** 2)\n\n    if scale_scores:\n        q75, q25 = np.percentile(a_score, [75, 25])\n        iqr = q75 - q25\n        median = np.median(a_score)\n        a_score = (a_score - median) / (1+iqr)\n\n    anomaly_scores[:, i] = a_score\n    df[f\"A_Score_{i}\"] = a_score\n\nanomaly_scores = np.mean(anomaly_scores, 1)\ndf['A_Score_Global'] = anomaly_scores","metadata":{"id":"esXBxwVGGkEo","outputId":"8d424eea-a05a-47ac-d3b1-1454f6175988","execution":{"iopub.status.busy":"2023-04-30T08:36:08.049781Z","iopub.execute_input":"2023-04-30T08:36:08.050561Z","iopub.status.idle":"2023-04-30T08:36:08.112122Z","shell.execute_reply.started":"2023-04-30T08:36:08.050524Z","shell.execute_reply":"2023-04-30T08:36:08.111056Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(900, 27)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  if __name__ == \"__main__\":\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_data = df.to_csv(f'EPOCH{EPOCHS}_WindowSIZE{Window}_windowgap{Window_gap}_contrastive.csv', index = True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:08.113789Z","iopub.execute_input":"2023-04-30T08:36:08.114556Z","iopub.status.idle":"2023-04-30T08:36:08.258561Z","shell.execute_reply.started":"2023-04-30T08:36:08.114502Z","shell.execute_reply":"2023-04-30T08:36:08.257397Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"     Forecast_0   Recon_0  True_0  A_Score_0  Forecast_1   Recon_1    True_1  \\\n0     -0.965657 -1.015607    -1.0  -0.015588    0.974439  0.779439  0.999906   \n1     -0.960321 -1.015424    -1.0  -0.010713    0.996448  0.777897  1.464000   \n2     -0.983553 -1.014767    -1.0  -0.033310    1.141349  0.776387  1.704049   \n3     -1.008280 -1.015226    -1.0  -0.040602    1.258994  0.774640  1.702518   \n4     -1.002583 -1.015909    -1.0  -0.045344    1.238525  0.774462  1.700952   \n..          ...       ...     ...        ...         ...       ...       ...   \n895   -0.943896 -1.024294    -1.0   0.013215    0.110521  0.732306 -0.953519   \n896   -0.944054 -1.024294    -1.0   0.013065    0.079356  0.731669 -0.955803   \n897   -0.949702 -1.023164    -1.0   0.006654    0.086554  0.734089 -0.958170   \n898   -0.967217 -1.022681    -1.0  -0.010371    0.039541  0.734854 -0.960561   \n899   -0.980469 -1.020970    -1.0  -0.024526    0.008995  0.735019 -0.960561   \n\n     A_Score_1  Forecast_2   Recon_2  ...  A_Score_24  Forecast_25  Recon_25  \\\n0    -0.373570   -0.841103 -0.929307  ...    0.171058    -0.898499 -0.967349   \n1    -0.082411   -0.820523 -0.927413  ...    0.167199    -0.889103 -0.967252   \n2     0.025591   -0.786817 -0.926302  ...    0.172885    -0.909368 -0.967698   \n3    -0.012567   -0.770888 -0.926479  ...    0.167805    -0.923789 -0.968064   \n4    -0.006949   -0.773006 -0.927181  ...    0.171153    -0.920454 -0.968131   \n..         ...         ...       ...  ...         ...          ...       ...   \n895   0.429587   -1.005333 -0.935478  ...    0.013735    -0.891700 -0.973582   \n896   0.420852   -1.007311 -0.935843  ...   -0.287280    -0.889603 -0.973534   \n897   0.425455   -1.007681 -0.935833  ...   -0.463282    -0.895732 -0.973362   \n898   0.412154   -1.031827 -0.936037  ...   -0.452199    -0.905330 -0.973296   \n899   0.402410   -1.058931 -0.935456  ...   -0.397764    -0.914110 -0.973051   \n\n      True_25  A_Score_25  Forecast_26  Recon_26   True_26  A_Score_26  \\\n0   -0.999133    0.015924    -0.806517 -0.790667 -1.000000   -0.091934   \n1   -0.999133    0.024665    -0.794978 -0.789414 -1.000000   -0.083600   \n2   -0.999133    0.005594    -0.821488 -0.788095 -1.000000   -0.100012   \n3   -0.999133   -0.008022    -0.806698 -0.788822 -1.000000   -0.090850   \n4   -0.999133   -0.005013    -0.789377 -0.789622 -1.000000   -0.080087   \n..        ...         ...          ...       ...       ...         ...   \n895  1.000000    3.453228    -0.042576 -0.811072 -1.000000    0.392476   \n896  1.000000    3.451254     0.018884 -0.810970 -1.000000    0.432583   \n897  1.000000    3.456739     0.005084 -0.809523 -0.130435    0.176346   \n898  1.000000    3.465516     0.120462 -0.808148 -1.000000    0.500599   \n899  1.000000    3.473375     0.105236 -0.804866 -1.000000    0.492818   \n\n     A_Score_Global  \n0         -0.069481  \n1         -0.041279  \n2          0.022968  \n3          0.014766  \n4         -0.069669  \n..              ...  \n895        0.274089  \n896        0.180957  \n897        0.173618  \n898        0.196042  \n899        0.233227  \n\n[900 rows x 109 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Forecast_0</th>\n      <th>Recon_0</th>\n      <th>True_0</th>\n      <th>A_Score_0</th>\n      <th>Forecast_1</th>\n      <th>Recon_1</th>\n      <th>True_1</th>\n      <th>A_Score_1</th>\n      <th>Forecast_2</th>\n      <th>Recon_2</th>\n      <th>...</th>\n      <th>A_Score_24</th>\n      <th>Forecast_25</th>\n      <th>Recon_25</th>\n      <th>True_25</th>\n      <th>A_Score_25</th>\n      <th>Forecast_26</th>\n      <th>Recon_26</th>\n      <th>True_26</th>\n      <th>A_Score_26</th>\n      <th>A_Score_Global</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.965657</td>\n      <td>-1.015607</td>\n      <td>-1.0</td>\n      <td>-0.015588</td>\n      <td>0.974439</td>\n      <td>0.779439</td>\n      <td>0.999906</td>\n      <td>-0.373570</td>\n      <td>-0.841103</td>\n      <td>-0.929307</td>\n      <td>...</td>\n      <td>0.171058</td>\n      <td>-0.898499</td>\n      <td>-0.967349</td>\n      <td>-0.999133</td>\n      <td>0.015924</td>\n      <td>-0.806517</td>\n      <td>-0.790667</td>\n      <td>-1.000000</td>\n      <td>-0.091934</td>\n      <td>-0.069481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.960321</td>\n      <td>-1.015424</td>\n      <td>-1.0</td>\n      <td>-0.010713</td>\n      <td>0.996448</td>\n      <td>0.777897</td>\n      <td>1.464000</td>\n      <td>-0.082411</td>\n      <td>-0.820523</td>\n      <td>-0.927413</td>\n      <td>...</td>\n      <td>0.167199</td>\n      <td>-0.889103</td>\n      <td>-0.967252</td>\n      <td>-0.999133</td>\n      <td>0.024665</td>\n      <td>-0.794978</td>\n      <td>-0.789414</td>\n      <td>-1.000000</td>\n      <td>-0.083600</td>\n      <td>-0.041279</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.983553</td>\n      <td>-1.014767</td>\n      <td>-1.0</td>\n      <td>-0.033310</td>\n      <td>1.141349</td>\n      <td>0.776387</td>\n      <td>1.704049</td>\n      <td>0.025591</td>\n      <td>-0.786817</td>\n      <td>-0.926302</td>\n      <td>...</td>\n      <td>0.172885</td>\n      <td>-0.909368</td>\n      <td>-0.967698</td>\n      <td>-0.999133</td>\n      <td>0.005594</td>\n      <td>-0.821488</td>\n      <td>-0.788095</td>\n      <td>-1.000000</td>\n      <td>-0.100012</td>\n      <td>0.022968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.008280</td>\n      <td>-1.015226</td>\n      <td>-1.0</td>\n      <td>-0.040602</td>\n      <td>1.258994</td>\n      <td>0.774640</td>\n      <td>1.702518</td>\n      <td>-0.012567</td>\n      <td>-0.770888</td>\n      <td>-0.926479</td>\n      <td>...</td>\n      <td>0.167805</td>\n      <td>-0.923789</td>\n      <td>-0.968064</td>\n      <td>-0.999133</td>\n      <td>-0.008022</td>\n      <td>-0.806698</td>\n      <td>-0.788822</td>\n      <td>-1.000000</td>\n      <td>-0.090850</td>\n      <td>0.014766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.002583</td>\n      <td>-1.015909</td>\n      <td>-1.0</td>\n      <td>-0.045344</td>\n      <td>1.238525</td>\n      <td>0.774462</td>\n      <td>1.700952</td>\n      <td>-0.006949</td>\n      <td>-0.773006</td>\n      <td>-0.927181</td>\n      <td>...</td>\n      <td>0.171153</td>\n      <td>-0.920454</td>\n      <td>-0.968131</td>\n      <td>-0.999133</td>\n      <td>-0.005013</td>\n      <td>-0.789377</td>\n      <td>-0.789622</td>\n      <td>-1.000000</td>\n      <td>-0.080087</td>\n      <td>-0.069669</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>-0.943896</td>\n      <td>-1.024294</td>\n      <td>-1.0</td>\n      <td>0.013215</td>\n      <td>0.110521</td>\n      <td>0.732306</td>\n      <td>-0.953519</td>\n      <td>0.429587</td>\n      <td>-1.005333</td>\n      <td>-0.935478</td>\n      <td>...</td>\n      <td>0.013735</td>\n      <td>-0.891700</td>\n      <td>-0.973582</td>\n      <td>1.000000</td>\n      <td>3.453228</td>\n      <td>-0.042576</td>\n      <td>-0.811072</td>\n      <td>-1.000000</td>\n      <td>0.392476</td>\n      <td>0.274089</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>-0.944054</td>\n      <td>-1.024294</td>\n      <td>-1.0</td>\n      <td>0.013065</td>\n      <td>0.079356</td>\n      <td>0.731669</td>\n      <td>-0.955803</td>\n      <td>0.420852</td>\n      <td>-1.007311</td>\n      <td>-0.935843</td>\n      <td>...</td>\n      <td>-0.287280</td>\n      <td>-0.889603</td>\n      <td>-0.973534</td>\n      <td>1.000000</td>\n      <td>3.451254</td>\n      <td>0.018884</td>\n      <td>-0.810970</td>\n      <td>-1.000000</td>\n      <td>0.432583</td>\n      <td>0.180957</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>-0.949702</td>\n      <td>-1.023164</td>\n      <td>-1.0</td>\n      <td>0.006654</td>\n      <td>0.086554</td>\n      <td>0.734089</td>\n      <td>-0.958170</td>\n      <td>0.425455</td>\n      <td>-1.007681</td>\n      <td>-0.935833</td>\n      <td>...</td>\n      <td>-0.463282</td>\n      <td>-0.895732</td>\n      <td>-0.973362</td>\n      <td>1.000000</td>\n      <td>3.456739</td>\n      <td>0.005084</td>\n      <td>-0.809523</td>\n      <td>-0.130435</td>\n      <td>0.176346</td>\n      <td>0.173618</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>-0.967217</td>\n      <td>-1.022681</td>\n      <td>-1.0</td>\n      <td>-0.010371</td>\n      <td>0.039541</td>\n      <td>0.734854</td>\n      <td>-0.960561</td>\n      <td>0.412154</td>\n      <td>-1.031827</td>\n      <td>-0.936037</td>\n      <td>...</td>\n      <td>-0.452199</td>\n      <td>-0.905330</td>\n      <td>-0.973296</td>\n      <td>1.000000</td>\n      <td>3.465516</td>\n      <td>0.120462</td>\n      <td>-0.808148</td>\n      <td>-1.000000</td>\n      <td>0.500599</td>\n      <td>0.196042</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>-0.980469</td>\n      <td>-1.020970</td>\n      <td>-1.0</td>\n      <td>-0.024526</td>\n      <td>0.008995</td>\n      <td>0.735019</td>\n      <td>-0.960561</td>\n      <td>0.402410</td>\n      <td>-1.058931</td>\n      <td>-0.935456</td>\n      <td>...</td>\n      <td>-0.397764</td>\n      <td>-0.914110</td>\n      <td>-0.973051</td>\n      <td>1.000000</td>\n      <td>3.473375</td>\n      <td>0.105236</td>\n      <td>-0.804866</td>\n      <td>-1.000000</td>\n      <td>0.492818</td>\n      <td>0.233227</td>\n    </tr>\n  </tbody>\n</table>\n<p>900 rows × 109 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # actual = smap_data_test_norm[Window:]\n# actual_1 = my_data_test_norm[Window:]\n\n# print(actual_1.shape)\n\n# anomaly_scores_1 = np.zeros_like(actual_1)\n# df_1 = pd.DataFrame()\n# for i in range(preds.shape[1]):\n#     df_1[f\"Forecast_{i}\"] = preds_1[:, i]\n#     df_1[f\"Recon_{i}\"] = recons_1[:, i]\n#     df_1[f\"True_{i}\"] = actual_1[:, i]\n#     a_score = np.sqrt((preds_1[:, i] - actual_1[:, i]) ** 2) + np.sqrt(\n#         (recons_1[:, i] - actual_1[:, i]) ** 2)\n\n#     if scale_scores:\n#         q75, q25 = np.percentile(a_score, [75, 25])\n#         iqr = q75 - q25\n#         median = np.median(a_score)\n#         a_score = (a_score - median) / (1+iqr)\n\n#     anomaly_scores[:, i] = a_score\n#     df_1[f\"A_Score_{i}\"] = a_score\n\n# anomaly_scores_1 = np.mean(anomaly_scores_1, 1)\n# df_1['A_Score_Global'] = anomaly_scores_1","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:36:08.260480Z","iopub.execute_input":"2023-04-30T08:36:08.260879Z","iopub.status.idle":"2023-04-30T08:36:08.266496Z","shell.execute_reply.started":"2023-04-30T08:36:08.260842Z","shell.execute_reply":"2023-04-30T08:36:08.265224Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tTV8rElqGloB","outputId":"bd18f190-9f0f-4703-fad7-04ea676d0bac","trusted":true},"execution_count":null,"outputs":[]}]}